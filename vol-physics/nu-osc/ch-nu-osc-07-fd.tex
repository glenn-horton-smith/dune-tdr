\section{Far Detector and Uncertainties}
%{\it Assigned to:} {\bf Dan Cherdack} with contributions from Nick Grant, Leigh Whitehead, Callum Wilkinson, Elizabeth Worcester and Tingjun Yang.
\label{sec:physics-lbnosc-FD}
%This section describes assumptions in the Near Detector simulation and reconstruction. Some thought has to go into the connection to the Far Detector chapter in the TDR.

%\begin{itemize}
%    \item Simulations - TY 
%    \item Reconstruction and kinematic variables including energy reconstruction - TY, NG 
%    \item Event selections (CVN) - LW
%    \item Samples - EW, CW
%    \item Detector response systematic uncertainties - DDC
%    \item Connection to flux and cross section systematic uncertainties
%\end{itemize}
\fixme{Needs intro text to Far Detector} 

\subsection{Simulation}
The neutrino samples were simulated using a smaller version of the full 10 kt far detector geometry. This geometry is 13.9 m long, 12 m high and 13.3 m wide, which consists of 12 APAs and 24 TPCs. The reference flux was used (Section~\ref{sec:physics-lbnosc-flux}) and samples were produced with both the forward-horn-current (neutrino enhanced) and inverted-horn-current (antineutrino enhanced) beam configurations. Three samples were generated. The first sample keeps the original neutrino flavor in the beam. The second sample converts all the muon neutrinos to electron neutrios. The third sample converts all the muon neutrinos to tau neutrinos. {\sc genie} \todo{name genie version} was used to model the neutrino-argon interactions in the volume of cryostat. The produced secondary particles were propagated in the detector through {\sc geant}. The ionization electrons and scintillation light were digitized to produce signals in the wire planes and photon detectors. More details on the simulation can be found in the Physics Tools and Methods chapter~\ref{}.

\subsection{Event reconstruction and kinematic variables}
The first step in the reconstruction is to convert the raw signal from each wire to a standard (e.g. Gaussian) shape. This is achieved by passing the raw data through a calibrated deconvolution algorithm to remove the impact of the LArTPC electric field and electronics responses from the measured signal.

The hit-finding algorithm scans the processed wire waveform looking for local minima. If a minimum is found, the algorithm follows the waveform after this point until it finds a local maximum. If the maximum is above a specified threshold, the program scans to the next local minimum and identifies this region as a hit. Hits are fit with a Gaussian function whose features identify the correct position (time coordinate), width and height and area (deposited charge) of the hit. A single Gaussian function is used to describe hits produced by isolated single particles. Multiple Gaussian functions are used to describe hits in a region where there are overlapping particles (e.g. around neutrino interaction vertex). The reconstructed hits are input to the CVN event selection described later.

Pattern recognition algorithms (Pandora and PMA) define clusters as hits that may be grouped together due to proximity to one another. Clusters from different planes are matched to form high-level objects such as tracks and showers, which are used as input to reconstruct the neutrino energy. More details on the reconstruction can be found in the Physics Tools and Methods chapter.

% Neutrino energy reconstruction

The energy of the incoming neutrino in charged-current events is estimated by adding the reconstructed lepton and hadronic energies. 
If the event is selected as $\nu_{\mu}$ CC, the 
neutrino energy is estimated as the sum of the energy of the longest reconstructed track and the hadronic energy. The energy of the longest reconstructed track is estimated from its 
range if the track is contained in the detector, and this is calibrated using simulated $\nu_{\mu}$ CC events. If the longest track exits the detector, its energy is estimated from 
multi-Coulomb scattering, and corrected using simulated events. The hadronic energy is estimated from the charges of reconstructed hits that 
are not in the longest track, and corrections are applied to each hit charge for recombination and the electron lifetime. An additional correction is then made to the hadronic energy to account for missing energy due to neutral particles and final-state interactions, and this is done using simulated events. 

If the event is selected as $\nu_{e}$ CC, the energy of the 
neutrino is estimated as the sum of the energy of the reconstructed shower with the highest energy and the hadronic energy. The former is estimated from the charges of the reconstructed 
hits in the shower, and the latter from the hits not in the shower; the recombination and electron lifetime corrections are applied to the charge of each hit. Subsequently the shower 
energy is corrected using simulated events, and the missing energy correction is applied to the hadronic energy.

The fractional residuals of reconstructed $\nu_{e}$ energy in $\nu_{e}$ CC events are shown in figure \ref{fig:enresnue}, and the biases and resolutions of reconstructed neutrino energy 
are summarised in table \ref{tab:ressummary}.

\begin{figure}[h]
    \centering
      %  \includegraphics[width=0.55\textwidth]{EnergyResNue.eps}
        \caption{Fractional residuals of reconstructed $\nu_{e}$ energy in $\nu_{e}$ CC events}
        \label{fig:enresnue}
\end{figure}

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline  
 Event selection  &   Bias (\%) & Resolution (\%) \\ \hline
\hline
 $\nu_{\mu}$ CC with contained track  &   -1  &  18   \\ \hline
 $\nu_{\mu}$ CC with exiting track  &  -4   &  20 \\ \hline
 $\nu_{e}$ CC    &  0 & 13    \\ \hline
\end{tabular}
\caption{Summary of biases and resolutions of reconstructed neutrino energy}
\label{tab:ressummary}
\end{center}
\end{table}

% Start DUNE CVN event selection subsection from Leigh and Saul

\subsection{DUNE CVN event selection}
The DUNE Convolutional Visual Network (CVN) classifies neutrino interactions in the DUNE FD through image recognition techniques. In general terms it is a convolutional neural network (CNN). Similar techniques have been demonstrated to outperform traditional event reconstruction-based methods to classify neutrino interactions~\cite{novacvn}.

\subsubsection{Network architecture}
The CVN is based on the SE-ResNet architecture, which consists of a standard ResNet (Residual neural network) architecture~\cite{He-et-al-2015-deep} along with Squeeze-and-Excitation blocks~\cite{Hu-et-al-2017-squeeze}. Residual neural networks allow the $n^{th}$ layer access to the output of both the $(n-1)^{th}$ layer and the $(n-k)^{th}$ layer via a residual connection, where $k$ is a positive integer $>=2$. This is an important feature for the DUNE CVN as it allows the fine-grained detail of a LArTPC encoded in the input images to be propagated further into the CVN than would be possible using a traditional CNN such as the GoogLeNet (also called Inception v1)~\cite{GoogLeNet} inspired network used by NOvA~\cite{novacvn}.

The DUNE CVN differs from the architectures of other residual networks discussed in the literature in the following ways:

\begin{itemize}
    \item The input and the shallower layers of the CVN are forked into three branches - one for each view - to let the model learn parameters from each individual view (see Section~\ref{sec:cvn:inputs} for more details). We merge the outputs of the three branches by using a concatenation layer that works as input for the deeper layers of the model, as is shown in Figure~\ref{fig:cvnarchitecture}.
    
    \item The CVN returns probabilities for each event through seven individual outputs (see Section~\ref{sec:cvn:outputs} and Figure~\ref{fig:cvnarchitecture} for more details). Since the deeper layers of the network share the model parameters corresponding to those layers, some outputs might take advantage of the learning process of other outputs to improve their performance. Also, a multi-output network lets us weight the outputs in order to make the network pay more attention to some specific outputs (see Section~\ref{sec:cvn:training} for more details). The summed probability of each individual output set is one.
    
    \item Each of the three branches (blocks 1-2, the shallower layers of the architecture shown in Figure~\ref{fig:cvnarchitecture}) consists of 7 convolutional layers, while the deeper layers (blocks 3-N in Figure~\ref{fig:cvnarchitecture}) consist of 29 convolutional layers, making a total of 50 layers for the entire network.

\end{itemize}

\begin{figure}
    \centering
%    \begin{tabular}{cc}
		\includegraphics[scale=0.6]{cvn_architecture.pdf}
%	\end{tabular}
	\caption{Simplified diagram of the DUNE CVN architecture showing the three input images, an overview of the convolutional layers and the seven output categories.}
    \label{fig:cvnarchitecture}
\end{figure}

\subsubsection{Inputs to the CVN}
\label{sec:cvn:inputs}
Three images of the neutrino interactions are built with one image for each of the three wire planes. These images are produced using the reconstructed hits on the individual wire planes and are not dependent on any further downstream reconstruction algorithms. The images (500$\times$500 pixels each) are produced in the (wire, time) parameter space where the wire is the wire channel number and the time is the peak time of the reconstructed hit measured in TDCs. An example 2.2\,GeV CC$\nu_e$ interaction with a visible electron shower and proton track is shown in all three views in Fig.~\ref{fig:cvn_views} demonstrating the fine-grained detail available from the LArTPC technology.

\begin{figure}[htb] 
    \centering
    \begin{tabular}{ccc}
	\includegraphics[scale=0.23]{cvn_nue_view0.png} &
	\includegraphics[scale=0.23]{cvn_nue_view1.png} &
    \includegraphics[scale=0.23]{cvn_nue_view2.png}
	\end{tabular}
	\caption{A 2.2\,GeV CC$\nu_e$ interaction shown in the three readout views of the DUNE LArTPCs. The horizontal axis shows the wire number of the readout plane and the vertical axis shows time. The colour scale shows the charge of the energy deposits on the wires.}
	\label{fig:cvn_views}
\end{figure}

\subsubsection{Training the CVN}
\label{sec:cvn:training}
\fixme{Potentially too much detail}
The CVN was trained using Keras \cite{Chollet-et-al-2015-keras} 2.2.0 on top of Tensorflow \cite{Abadi-et-al-2016-tensorflow} 1.8.0, on 8 NVIDIA Tesla V100 GPUs. The optimizer used was Stochastic Gradient Descent (SGD), with a mini-batch size of 64 events (192 views), a learning rate of 0.1 (divided by 10 when the error plateaus, as suggested in \cite{He-et-al-2015-deep}), a weight decay of 0.0001 and a momentum of 0.9. The CVN was trained and validated using over three million interactions (corresponding to nine million individual images) from a single Monte Carlo sample, and tested on approximately three million events from an independent Monte Carlo sample.

The individual loss functions for the different outputs that we used for training the model, as well as the overall loss function, are given below:

\begin{itemize}
    \item Neutrino/antineutrino loss function ($J_{1}$): binary cross-entropy.

    \begin{equation}
    J_{1} = - \frac{1} m \sum_{i=1}^{m} y^{(i)} \log (\hat{y}^{(i)}) + (1 - y^{(i)}) \log (1 -\hat{y}^{(i)})
    \end{equation}

    \item Flavour, interaction type, protons, pions, pizeros, neutrons loss functions ($J_{2}$, $J_{3}$, $J_{4}$, $J_{5}$, $J_{6}$, and $J_{7}$, respectively): categorical cross-entropy.

    \begin{equation}
    J_{2} = J_{3} = J_{4} = J_{5} = J_{6} = J_{7} = - \frac{1} m \sum_{i=1}^{m} \sum_{j=1}^{c} y_{j}^{(i)} \log \hat{y}_{j}^{(i)}
    \end{equation}

    \item Overall loss function:

    \begin{equation}
    J = w_{1} J_{1} + w_{2} J_{2} + w_{3} J_{3} + w_{4} J_{4} + w_{5} J_{5} + w_{6} J_{6} + w_{7} J_{7}
    \end{equation}

    \item Where:
        \begin{itemize}
        \item $y$: true output values.
        \item $\hat{y}$: predicted output values.
%        \item $m$: number of training examples \{($x^{(1)}$, $y^{(1)}$), ($x^{(2)}$, $y^{(2)}$), ... , ($x^{(m)}$, $y^{(m)}$)\}.
\item $m$: number of training examples ($x^{(1)}$, $y^{(1)}$), ($x^{(2)}$, $y^{(2)}$), ... , ($x^{(m)}$, $y^{(m)}$).
%        \item $c$: number of classes \{$y_{1}$, $y_{2}$, ... , $y_{c}$\}.
        \item $c$: number of classes $y_{1}$, $y_{2}$, ... , $y_{c}$.
        \item $w$: output weights; 1-dimensional array of length seven.
    \end{itemize}
\end{itemize}
\fixme{Anne had compile issue with the curly brackets in the previous itemize list so I removed them}

The CVN was trained for 18 epochs and similar classification performance was obtained for the training and test samples.

\subsubsection{Outputs from the CVN}
\label{sec:cvn:outputs}
\fixme{Potentially too much detail}
The CVN has the following seven output categories:

\begin{enumerate}
    \item Name: `nubar', 1 neuron: returns the probability for each event to be an antineutrino. Thus, $P(nubar)=0$ means that the event is a neutrino and $P(nubar)=1$ that it is an antineutrino.
    \item Name: `flavour', 4 neurons: returns probabilities for each event to be in the following flavours: CC $\nu_\mu$, CC $\nu_e$, CC $\nu_\tau$, NC.
    \item Name: `interaction', 4 neurons: returns probabilities for each event to be in the following interaction types: CC QE, CC Res, CC DIS, CC Other. 
    \item Name: `protons', 4 neurons: returns probabilities for each event to contain the following number of protons: 0, 1, 2, $>$2.
    \item Name: `pions', 4 neurons: returns probabilities for each event to contain the following number of pions: 0, 1, 2, $>$2.
    \item Name: `pizeros', 4 neurons): returns probabilities for each event to contain the following number of pizeros: 0, 1, 2, $>$2.
    \item Name: `neutrons', 4 neurons: returns probabilities for each event to contain the following number of neutrons: 0, 1, 2, $>$2.
\end{enumerate}

\subsubsection{Neutrino flavor identification}
The primary goal of the CVN is to accurately identify charged-current electron neutrino interactions and charged-current muon neutrino interactions to allow for the selection of the samples required for the neutrino oscillation analysis. The CC$\nu_e$ probability distribution, $P(\nu_e)$, and the CC$\nu_\mu$ probability distribution, $P(\nu_\mu)$, are shown on the left and right of Fig.~\ref{fig:cvnprob}, respectively. Excellent separation between the signal and background interactions is seen in both cases.

\begin{figure}
    \centering
    \begin{tabular}{cc}
	%	\includegraphics[width=0.45\linewidth]{cvn_nue_prob.eps} &
	%	\includegraphics[width=0.45\linewidth]{cvn_numu_prob.eps} 
	\end{tabular}
	\caption{The neutrino flavour classification probabilities $P(\nu_e)$ (left) and $P(\nu_\mu)$ (right) for FHC-mode simulated CC$\nu_\mu$ (purple), CC$\nu_e$ (green), CC$\nu_\tau$ (cyan) and NC (orange) neutrino interactions.}
    \label{fig:cvnprob}
\end{figure}

The CC$\nu_e$ event selection requires $P(\nu_e) > 0.7$ for an interaction to be considered a CC$\nu_e$ candidate event. Similarly, interactions are selected as CC$\nu_\mu$ candidates if $P(\nu_\mu) > 0.5$. Note that since all of the flavour classification probabilities must sum to one, these two samples are completely independent. The same selection criteria are used for both FHC and RHC event selections.

Figure~\ref{fig:nueeff} shows the efficiency as a function of reconstructed energy (under the electron neutrino hypothesis) for the $\nu_e$ event selection. (some comments on the plot). Figure~\ref{fig:numueff} shows the corresponding selection efficiency for the $\nu_\mu$ event selection.

\begin{figure}
    \centering
    \begin{tabular}{cc}
		\includegraphics[scale=0.22]{cvn_placeholder.pdf} &
		\includegraphics[scale=0.22]{cvn_placeholder.pdf} 
	\end{tabular}
	\caption{The CC$\nu_e$ selection efficiency for FHC-mode (left) and RHC-mode (right) simulation with the criterion $P(\nu_e) > 0.7$. (Describe the various colours).}
    \label{fig:nueeff}
\end{figure}

\begin{figure}
    \centering
    \begin{tabular}{cc}
		\includegraphics[scale=0.22]{cvn_placeholder.pdf} &
		\includegraphics[scale=0.22]{cvn_placeholder.pdf} 
	\end{tabular}
	\caption{The CC$\nu_\mu$ selection efficiency for FHC-mode (left) and RHC-mode (right) simulation with the requirement $P(\nu_\mu) > 0.5$. (Describe the various colours).}
    \label{fig:numueff}
\end{figure}

\subsubsection{Exclusive final states}
The CVN has four outputs that count the number of final-state particles for the following species: protons, charged pions, neutral pions and neutrons. Neutrino interactions with different final-state particles can have varying energy resolutions depending on the complexity and particle multiplicity of the interaction. The ability to accurately select exclusive final-states will allow for those interactions with very good energy resolution to be fully exploited in the oscillation fit to improve the sensitivity of the analysis.

The individual output probabilities from the CVN can be multiplied together to give probabilities for exclusive selections. For example, Fig.~\ref{fig:exclusive} shows the $\nu_\mu$ CC1p probability on the left, and the NC$\pi^0$ probability on the right.
\begin{figure}
    \centering
    \begin{tabular}{cc}
	%	\includegraphics[width=0.475\linewidth]{cvn_numu1proton0pions0pizeros.eps} &
	%	\includegraphics[width=0.475\linewidth]{cvn_nc1proton0pions1pizeros.eps} 
	\end{tabular}
	\caption{The $\nu_\mu$ CC1p (left) and NC$\pi^0$ (right) probability distributions from the CVN. In both cases the signal interactions are shown by the purple curve and all backgrounds are shown in green.}
    \label{fig:exclusive}
\end{figure}

\subsubsection{Robustness}
A common concern about the applications of Deep Learning in high energy physics is the difference in performance between data and simulation.

The performance of the CVN has been tested using data from ProtoDUNE-SP~\cite{Abi:2017aow}. ProtoDUNE-SP was not exposed to a neutrino beam but collected cosmic ray muons and charged particles from a beam including electrons and positrons. Images were constructed from the hits of individual cosmic muon tracks reconstructed with a length over 1\,m, such that they can mimic a simple CC $\nu_\mu$ interaction. The images were then classified by the CVN, where the expected classification is CC $\nu_\mu$ with no other final-state particles. The probability for a CC $\nu_\mu$ interaction with no hadronic system is obtained by the product of a number of the CVN outputs as
\begin{equation}
P(CC\nu_\mu0) = P(CC\nu_\mu)P(0p)P(0\pi^\pm)P(0\pi^0)P(0n).    
\end{equation} 
The $P(CC\nu_\mu0)$ distribution is shown in Fig.~\ref{fig:protodunecvn} for ProtoDUNE-SP cosmic muon data and simulation.

\begin{figure}
    \centering
    \includegraphics[scale=0.5]{cvn_protodata_mc.pdf}
    \caption{The probability for classifying an event as a CC$\nu_\mu$ interaction with no hadronic final state for a sample of cosmic ray muons over 1\,m in length in ProtoDUNE data and simulation. (Update with higher stats and after calibrations etc)}
    \label{fig:protodunecvn}
\end{figure}

\subsection{FD Samples}

Place holder for the final FD samples. Will have 4 Enu spectra plots for nue/numu in FHC/RHC mode.

\subsection{FD Systematics}
\fixme{Expand/Write section as results are produced}
FD systematics are those that affect the energy reconstruction (energy scale/bias, or energy resolution) or the efficiency. There are 3 categories of FD systematic being considered. The first is from interaction and FSI systematics. This is covered by the DUNErwt machinery, but the connection will be discussed here. The second is calibration uncertainties that will be based on input from the CalTF. This will also include the effects of inaccuracies from detector modelling (e.g. alignment) and detector failure modes (e.g. dead wires, electronics, etc.) Third is uncertainties on the detector model physics assumptions (i.e. GEANT4 uncertainties).  Currently Cafana is configured to fit energy scale and resolution systematics for the leptonic and hadronic componenents, as well as expanded FSI uncertainties in DUNErwt. These and other effects will also be explored by fake data (miscalibration effects via charge buildup, missing wire plains in various configurations, and moving energy in protons to neutrons are already planned). Explorations of the main source of GEANT4 errors will happen in the next couple weeks. Further discussion will have to wait for results on fitter development, and fitter performance evaluations during
Hack Days (Nov 15-17). This development and evaluation will allow us to see which effects dominate and how, and thus must be discussed in detail, versus what has a small effect and can be discussed briefly.


% End DUNE CVN event selection subsection

% \subsubsection{Simulation and Reconstruction Parameters}
% \subsubsection{Energy Reconstruction}
% \begin{itemize}
% \item New plots: Smearing matrices (Update to include latest Ereco)
% \item New plots: Muon, shower, hadronic, neutrino energy resolution and bias  (Update to include latest Ereco)
% \end{itemize}

% \subsection{Event Selections and Spectra}
% Descriptions and plots of efficiency, purity, sig/bkg discriminants, spectra for each selection:
% \begin{itemize}
% \item MVA Selections (Update to latest version)
% \item Pandora-based PID Selections (Update to latest version)
% \item CVN Selections (Update to latest version)
% \end{itemize}

% Tables:
% \begin{itemize}
% 	\item CDR Table 3.5: Nue/Nuebar appearance rates
% 	\item CDR Table 3.6: Numu/Numubar disappearance rates
% \end{itemize}